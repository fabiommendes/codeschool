## Worker Processes
# Set to auto (one worker per core) if running a dedicated Nginx instance.
# If the same physical machine runs Nginx, Django and the database, it is
# probably better to keep a single worker and leave the other cores to the
# more CPU intensive parts

worker_processes 1;


## Basic configurations

user nobody nogroup;
pid /tmp/nginx.pid;


## Number of connections

events {
    # Check the maximum with ulimit -n. This number can be as high as 65536
    worker_connections 1024;
    use epoll;
    multi_accept on;

    # You may want to turn on if worker_processes > 1
    accept_mutex off;
}


## HTTP requests and configuration

http {
    sendfile on;
    tcp_nopush on;
	tcp_nodelay on;
	keepalive_timeout 65;
	keepalive_requests 100000;

	## Mime-types
	include /etc/nginx/mime.types;
	default_type application/octet-stream;

	## SSL Settings
	ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE
	ssl_prefer_server_ciphers on;

	## Logging Settings
	access_log /var/log/nginx/access.log;
	error_log /var/log/nginx/error.log;

	## Gzip Settings
	gzip on;
	gzip_disable "msie6";
	gzip_min_length 1024;
	gzip_buffers 8 16k;
	gzip_types application/x-javascript text/css application/javascript text/javascript text/plain text/xml application/json application/vnd.ms-fontobject application/x-font-opentype application/x-font-truetype application/x-font-ttf application/xml font/eot font/opentype font/otf image/svg+xml image/vnd.microsoft.icon;
	gzip_vary on;
	gzip_comp_level 6;
	gzip_http_version 1.1;

    ## WSGI application server
    # This is the connection with the app server. If the nginx container is in
    # the same machine of the WSGI server container, it should communicate using
    # sockets. This is safer and faster than HTTP.
    #
    # If the proxy is not running in the same host machine as the WSGI
    # application, nginx must communicate using HTTP.
    upstream wsgi_app {
        # Socket-based configuration. Both containers should share the /sock/
        # mounting point
        server unix:///tmp/sock/webapp.sock fail_timeout=0;

        # HTTP based setup
        #ip_hash;
        #server http://localhost:8080 fail_timeout=1;
    }

    ## Nginx proxy
    server {
        listen 80 deferred;
        client_max_body_size 4G;
        server_name localhost;

        ## Static assets
        # We configure static assets (/static and /media) and define a special
        # caching behavior for /static
        location /static/ {
            alias /var/www/static/;
            open_file_cache max=1000 inactive=40s;
            open_file_cache_valid 60s;
            open_file_cache_min_uses 5;
            open_file_cache_errors off;
        }
        location /media/ {
            alias /var/www/media/;
        }

        ## Main entry point
        location = / {
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header Host $http_host;
            proxy_redirect off;
            proxy_pass http://wsgi_app;
        }
        location / {
            try_files $uri @proxy_to_app;
        }

        ## WSGI app server (will run something such as Django on gunicorn)
        location @proxy_to_app {
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header Host $http_host;
            proxy_redirect off;
            proxy_pass http://wsgi_app;
        }
    }
}
